{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fdeb227914c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ratings_25m\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'movieId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'userId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'liked'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-fdeb227914c0>\u001b[0m in \u001b[0;36mget_ratings_25m\u001b[0;34m(min_number_of_reviews)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_ratings_25m\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_number_of_reviews\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_movielens_25m\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_movielens_25m\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_number_of_reviews\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-fdeb227914c0>\u001b[0m in \u001b[0;36mread_movielens_25m\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_movielens_25m\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ratings.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mmovies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'movies.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmovies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, rows)\u001b[0m\n\u001b[1;32m   2429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2430\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2431\u001b[0;31m             \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2432\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_get_lines\u001b[0;34m(self, rows)\u001b[0m\n\u001b[1;32m   3183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3184\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mnew_row\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3185\u001b[0;31m                                 \u001b[0mnew_rows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3187\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = '/Users/kevinkurek/Desktop/GitHub/data-science/workspace/kevinkurek/RL/data/ml-25m'\n",
    "\n",
    "def read_movielens_25m():\n",
    "    ratings = pd.read_csv(os.path.join(DATA_PATH,'ratings.csv'), engine='python')\n",
    "    movies = pd.read_csv(os.path.join(DATA_PATH,'movies.csv'), engine='python')\n",
    "    movies = movies.join(movies.genres.str.get_dummies().astype(bool))\n",
    "    movies.drop('genres', inplace=True, axis=1)\n",
    "    df = ratings.join(movies, on='movieId', how='left', rsuffix='_movie')\n",
    "    return df\n",
    "\n",
    "def preprocess_movielens_25m(df, min_number_of_reviews=20000):\n",
    "    # remove ratings of movies with < N ratings. too few ratings will cause the recsys to get stuck in offline evaluation\n",
    "    movies_to_keep = pd.DataFrame(df.movieId.value_counts())\\\n",
    "        .loc[pd.DataFrame(df.movieId.value_counts())['movieId']>=min_number_of_reviews].index\n",
    "    df = df.loc[df['movieId'].isin(movies_to_keep)]\n",
    "    # shuffle rows to debias order of user ids\n",
    "    df = df.sample(frac=1)\n",
    "    # create a 't' column to represent time steps for the bandit to simulate a live learning scenario\n",
    "    df['t'] = np.arange(len(df))\n",
    "    df.index = df['t']\n",
    "    # rating >= 4.5 stars is a 'like', < 4 stars is a 'dislike'\n",
    "    df['liked'] = df['rating'].apply(lambda x: 1 if x >= 4.5 else 0)\n",
    "    return df\n",
    "\n",
    "def get_ratings_25m(min_number_of_reviews=20000):\n",
    "    df = read_movielens_25m()\n",
    "    df = preprocess_movielens_25m(df, min_number_of_reviews=20000)\n",
    "    return df\n",
    "\n",
    "df = get_ratings_25m()\n",
    "df = df[['timestamp', 'movieId', 'userId', 'liked']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0ca7abc090ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# initialze history with 50% like rate, 8 ratings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# this avoids stddev errors and prioritizes exploration of new posts in early iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'movieId'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'movieId'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m't'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "def replay_score(history, df, t, batch_size, recs):\n",
    "    \"\"\"\n",
    "    https://arxiv.org/pdf/1003.5956.pdf\n",
    "    replay score. reward if rec matches logged data, ignore otherwise.\n",
    "    I.E. If MAB recommended 5 movies & historical viewer data showed they watched 3 of the 5 then we'd\n",
    "    only pull the rewards for the 3 movies they played; [1, 0, 1] = liked, disliked, liked for example.\n",
    "    \"\"\"\n",
    "    # reward if rec matches logged data, ignore otherwise\n",
    "    actions = df[t:t+batch_size] # 100 possible movie matches at once\n",
    "    # Core of \"Reply\": Matching our bandit policy recommendations with actual viewer content at current timestep\n",
    "    actions = actions.loc[actions['movieId'].isin(recs)] # Number out of 100 movies that matched\n",
    "    actions['scoring_round'] = t\n",
    "    # add row to history if recs match logging policy\n",
    "    history = history.append(actions) # cumulatively grows as algo steps through time\n",
    "    action_liked = actions[['movieId', 'liked']]\n",
    "    return history, action_liked\n",
    "\n",
    "def ucb1_policy(df, t, ucb_scale=2.0, slate_size=5, bayes=True):\n",
    "    '''\n",
    "    Applies UCB1 policy to generate movie recommendations\n",
    "    Args:\n",
    "        df: dataframe. Dataset to apply UCB policy to.\n",
    "        ucb_scale: float. Most implementations use 2.0.\n",
    "        t: int. represents the current time step.\n",
    "    '''\n",
    "    scores = df[['movieId', 'liked']].groupby('movieId').agg({'liked': ['mean', 'count', 'std']})\n",
    "    scores.columns = ['mean', 'count', 'std']\n",
    "    if bayes:\n",
    "        # Bayes UCB\n",
    "        scores['ucb'] = scores['mean'] + (ucb_scale * scores['std'] / np.sqrt(scores['count']))\n",
    "    else:\n",
    "        # Regular UCB\n",
    "        scores['ucb'] = scores['mean'] + np.sqrt(\n",
    "                ( (2 * np.log10(t)) /\n",
    "                    scores['count'] )\n",
    "                )\n",
    "    scores['movieId'] = scores.index\n",
    "    scores = scores.sort_values('ucb', ascending=False)\n",
    "    recs = scores.loc[scores.index[0:slate_size], 'movieId'].values\n",
    "    return recs\n",
    "\n",
    "# simulation params: slate size, batch size (number of events per training iteration)\n",
    "slate_size = 5 # ACTION: number of recommendations to show at once\n",
    "batch_size = 100 # STEP: number of values to step through at a time (note that 1 step at a time isn't efficient)\n",
    "\n",
    "# df = get_ratings_25m(min_number_of_reviews=1500)\n",
    "\n",
    "# initialize empty history for random policy\n",
    "# (the algorithm should be able to see all events and outcomes prior to the current timestep, but no current or future outcomes)\n",
    "# history = pd.DataFrame(data=None, columns=df.columns)\n",
    "# history = history.astype({'movieId': 'int32', 'liked': 'float'})\n",
    "\n",
    "# initialize history for UCB Policy\n",
    "# initialze history with 50% like rate, 8 ratings\n",
    "# this avoids stddev errors and prioritizes exploration of new posts in early iterations\n",
    "history = df.groupby('movieId').first()\n",
    "history['movieId'] = history.index\n",
    "history['t'] = 0\n",
    "history.index = history['t']\n",
    "history['liked'] = 1\n",
    "history = history[df.columns] # reorder columns to match logged data\n",
    "history2 = history.copy()\n",
    "history2['liked'] = 0\n",
    "history = history.append(history).append(history2).append(history2).append(history)\n",
    "history['scoring_round'] = 0\n",
    "display(history.head())\n",
    "\n",
    "# to speed this up, retrain the bandit every batch_size time steps\n",
    "# this lets us measure batch_size actions against a slate of recommendations rather than generating\n",
    "#      recs at each time step. this becomes necessary to reach a useful sample size with replay evaluation\n",
    "ucb_history = pd.DataFrame(data=None, columns = ['mean', 'count', 'std', 'ucb', 'movieId', 'iter']) # for post-analysis of ucbs over iterations\n",
    "max_time = df.shape[0] # total number of ratings to evaluate using the bandit\n",
    "print('Running algorithm')\n",
    "\n",
    "# initialize empty list for storing scores from each step\n",
    "rewards = []\n",
    "\n",
    "for t in range(max_time//batch_size):\n",
    "    t = t * batch_size\n",
    "    # POLICY: generate recommendations from a random policy\n",
    "#     recs = np.random.choice(df.movieId.unique(), size=(slate_size), replace=False)\n",
    "\n",
    "    # POLICY: Bayesian UCB\n",
    "    recs = ucb1_policy(df=history.loc[history.index<=t,], t=t/batch_size, ucb_scale=2.0, slate_size=slate_size, bayes=True)\n",
    "    print(recs) # 5 random movie ids\n",
    "    # send recommendations and dataset to a scoring function so the model can learn & adjust its policy in the next iteration\n",
    "    history, action_score = replay_score(history, df, t, batch_size, recs)\n",
    "    print(f\"Current history: \\n {history} \\n\")\n",
    "    print(f\"Current action: \\n {action_score} \\n\")\n",
    "    \n",
    "    if action_score is not None:\n",
    "        action_score = action_score.liked.tolist() # REWARD Pulls out 1 or 0, liked or disliked\n",
    "        rewards.extend(action_score)\n",
    "        print(f\"Cumulative Rewards at time t = {t}: \\n {rewards} \\n\")  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ucb1_policy(df, t, ucb_scale=2.0, bayes=True):\n",
    "    '''\n",
    "    Applies UCB1 policy to generate movie recommendations\n",
    "    Args:\n",
    "        df: dataframe. Dataset to apply UCB policy to.\n",
    "        ucb_scale: float. Most implementations use 2.0.\n",
    "        t: int. represents the current time step.\n",
    "    '''\n",
    "    scores = df[['movieId', 'liked']].groupby('movieId').agg({'liked': ['mean', 'count', 'std']})\n",
    "    scores.columns = ['mean', 'count', 'std']\n",
    "    if bayes:\n",
    "        scores['ucb'] = scores['mean'] + (ucb_scale * scores['std'] / np.sqrt(scores['count']))\n",
    "    else:\n",
    "        scores['ucb'] = scores['mean'] + np.sqrt(\n",
    "                (\n",
    "                    (2 * np.log10(t)) /\n",
    "                    scores['count']\n",
    "                )\n",
    "            )\n",
    "    scores['movieId'] = scores.index\n",
    "    scores = scores.sort_values('ucb', ascending=False)\n",
    "    recs = scores.loc[scores.index[0:args.n], 'movieId'].values\n",
    "    return recs\n",
    "\n",
    "recs = ucb1_policy(df=history.loc[history.t<=t,], t, ucb_scale=args.ucb_scale)\n",
    "history, action_score = score(history, df, t, args.batch_size, recs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
